{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance-based Learning (KNN)\n",
    "- Non-parametric models\n",
    "    - Instead of learning from the data and creating a function to fit the data, we're just putting the data into a database and simply look up for the value when we've a new X\n",
    "- Benefits\n",
    "    - Remembers (keeps data)\n",
    "    - Fast\n",
    "    - Simple \n",
    "- Cons\n",
    "    - Can overfit \n",
    "    - Unable to generalize\n",
    "        - These cons are solved with K Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Types of Distance Function (Calculation of Distances) in KNN**\n",
    "- These distances are used to calculate the nearest neighbours\n",
    "    - Euclidean\n",
    "    - Manhattan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN Bias**\n",
    "- Preference Bias\n",
    "    - Our belief about what makes a good hypothesis\n",
    "        - Locality\n",
    "            - Near points are similar\n",
    "        - Smoothness\n",
    "            - Averaging\n",
    "        - All features matter equally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Curse of Dimensionality**\n",
    "- As the number of features or dimensions grow, the amount of datathat we need to generalize accurately grows exponentially"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other stuff about KNN**\n",
    "- It is important to choose the right distance function\n",
    "    - Euclidean vs Manhattan\n",
    "- K = n \n",
    "    - Locally weighted regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "- Instance based learning\n",
    "- Lazy vs eager learning\n",
    "    - Lazy: knn\n",
    "        - Nearest neighbor: similarity (distance)\n",
    "- Classification vs regression\n",
    "    - KNN can handle both of them\n",
    "        - Notion of averaging\n",
    "- Locally weighted regression\n",
    "    - Can do any kind of regression we want to\n",
    "- Bellman's curse of dimensionality"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py3k]",
   "language": "python",
   "name": "Python [py3k]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
